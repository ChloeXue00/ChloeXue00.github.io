<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>城市NOA功能竞品分析 | </title>
<meta name="keywords" content="城市NOA, BEV, Occupancy Network, VLA, 视觉语言模型, 智能驾驶架构">
<meta name="description" content="城市NOA技术战局（上）：从BEV到VLA，拆解头部玩家技术路线
主要结论：
继2023–2024年BEV&#43;Transformer&#43;Occupancy Network架构成为智能驾驶的感知主流后，2025年起，行业正加速向更高级的**VLM（Vision-Language Model）与VLA（Vision-Language-Action）**模型演进。相较于传统BEV结构仅关注空间几何关系，VLM/VLA引入语言推理模块，可对标志、规则、指令进行语义理解，结合多模态输入（如摄像头图像、语音交互、交通文本信息），生成更泛化、更类人的行为决策。
芯片与算力能力成为支撑城市NOA架构升级的关键基础。2020年前后主流平台算力集中于144 TOPS，如今已普遍跃升至500 TOPS以上，高端平台如蔚来NX9031、理想Thor-U、小鹏图灵AI芯片等更达到千级算力，支撑端到端推理、大模型部署与多模态处理。自研芯片、自建智算中心、自主模型训练正成为具备战略自主能力车企的核心壁垒。
在感知侧，“视觉为主&#43;激光雷达补盲”已成为当前主流配置。视觉方案具备数据规模与算力适配优势，激光雷达则增强空间精度与安全冗余，尤其在无高精地图场景中具备更强稳定性。不同厂商依据策略选择单感知或多模态融合方案，构建安全容错体系。

产品背景

近年来，随着特斯拉AutoPilot不断进阶至FSD，辅助驾驶已从L0级定速巡航，逐步拓展至高速NOA，再迈入城市NOA阶段，覆盖更复杂多变的交通环境。智能驾驶正在从“技术亮点”转向“核心卖点”，显著影响消费者购车决策。
以小鹏和问界为例：小鹏G6智驾版配置占比超过70%，问界新M7的大定用户中也有60%以上选择搭载高阶智能驾驶方案。这一趋势标志着，中国智能驾驶市场已全面进入L2&#43;/NOA功能的规模化普及阶段。
L2&#43;辅助驾驶能力包括自适应巡航（ACC）、车道居中控制（LCC）、自动变道（ALC）、高速NOA等，城市NOA则在此基础上，扩展至非结构化路况中的红绿灯通行、环岛绕行、路口博弈等复杂决策工况，对感知精度、决策智能与系统泛化能力提出更高要求。
在城市NOA推进过程中，高精地图鲜度不足、覆盖受限、成本高昂等问题，成为核心瓶颈。为突破此限制，主流技术路线正在从依赖地图的规则驱动方案，全面转向端到端模型驱动 &#43; 自主环境建图 &#43; 多模态策略融合的新范式。
技术架构上，感知模块经历了从前向2D视角 → BEV建图 → Occupancy Network建模的迭代，决策控制模块也正由传统rule-based状态机，向基于神经网络的端到端行为预测发展。2025年起，VLM（视觉语言模型）和VLA（Vision-Language-Action）架构逐步上车，赋予系统语义理解与策略推理能力，成为当前算法演进的前沿方向。
本报告将围绕特斯拉、小鹏、理想、蔚来等具备自研能力的头部品牌，梳理其城市NOA技术路线演进路径，结合软硬件系统方案与市场落地节奏，探讨中国品牌如何在“从BEV到VLA”的产业跃迁中建立领先优势。

目标用户与使用场景

L2/L2&#43;辅助驾驶系统主要面向具备一定驾驶经验、希望在日常通勤或长途驾驶中降低疲劳、提升安全性的新能源车主及购车潜在用户。
这类用户普遍关注两个关键问题：
各品牌城市NOA在不同城市、路况下的表现差异；
智驾能力与整车价格之间的性价比。
智能驾驶的核心价值在于：在用户监管下，系统能够预判潜在风险、辅助完成复杂驾驶动作，从而减轻认知负担、降低事故风险。尤其在城市NOA场景中，系统需完成红绿灯识别、路口博弈、避让行人、自主换道等行为，对系统泛化能力、策略鲁棒性和人机交互体验提出更高要求。
因此，城市NOA不仅是“功能拓展”，更代表了整车系统智能化水平的“天花板”。

竞品分析

本篇章节主要对于特斯拉，以蔚来理想小鹏为代表的头部企业在“城市导航辅助驾驶功能”的进展上进行对比分析，除此之外还包括，硬件系统方案，软件算法，功能配置，交互逻辑，运营方案，亮点场景等对比。
3.1 调研洞察摘要
城市NOA的落地，标志着行业正从规则驱动向数据驱动、从模块化架构向端到端大模型架构转变。以下趋势尤为明显：
技术架构趋同： 特斯拉、小鹏、蔚来等主流厂商均采用BEV&#43;Transformer&#43;Occupancy Network感知结构，逐步引入端到端神经网络控制器替代传统状态机，提升整体智驾稳定性。
算力平台升级： 主流平台从原先144TOPS提升至500–1000TOPS以上，大算力平台成为支持端到端大模型部署的基础设施。
数据闭环能力强化： 具备自动采集、筛选、标注、仿真重建与在线训练能力的“数据-模型-闭环”体系，成为城市NOA性能提升的核心引擎。
用户体验导向增强： 城市NOA正加速从试点区域向全国多城落地，主机厂纷纷围绕“全国都能开、用户真愿用”目标，推动功能迭代与大模型泛化能力提升。
结论：在城市NOA成为新一代智能驾驶标配的背景下，能否构建“低成本、高泛化、大闭环”的自研体系，将成为厂商能否突围的核心分水岭。
3.2 技术方案演进与“去高精地图化”
高速NOA因场景结构稳定，长期采用规则驱动&#43;高精地图方式实现；而城市NOA因存在海量动态变量与非结构化场景，传统Rule-based方案难以覆盖，技术路线普遍演进为以下三个阶段：
基于高精地图的三段式结构： 感知–规划–控制，依赖静态地图与有限状态机；
BEV&#43;Transformer感知融合结构： 引入Occupancy Network构建3D空间占据图，提升遮挡处理与障碍识别能力；
端到端 &#43; 多模态语义推理架构（VLA）： 引入视觉语言模型、扩散策略网络、博弈推理模块等，实现感知–理解–决策一体化。
“去高精地图化”已成为城市NOA发展的行业共识，各家方案通过Occupancy Network、弱地图辅助、分布式建图等方式逐步替代静态地图依赖，以提升系统泛化能力与落地效率。
3.2.1 特斯拉技术演进：

自2014年发布AutoPilot 1.0以来，特斯拉持续引领辅助驾驶从规则驱动走向数据驱动、再走向端到端神经控制的范式演进。
HW1.0 &#43; Mobileye平台（2014–2016）： 初代AutoPilot基于Mobileye方案，支持基本的巡航与车道保持功能，但受限于单摄像头配置与规则逻辑，系统泛化能力有限。">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/%E5%9F%8E%E5%B8%82noa%E7%AB%9E%E5%93%81%E6%8A%80%E6%9C%AF%E5%85%A8%E6%99%AF%E4%B8%8A%E4%BB%8Ebev%E5%88%B0vla%E6%8B%86%E8%A7%A3%E7%90%86%E6%83%B3%E5%B0%8F%E9%B9%8F%E8%94%9A%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E5%88%86%E6%B0%B4%E5%B2%AD/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/%E5%9F%8E%E5%B8%82noa%E7%AB%9E%E5%93%81%E6%8A%80%E6%9C%AF%E5%85%A8%E6%99%AF%E4%B8%8A%E4%BB%8Ebev%E5%88%B0vla%E6%8B%86%E8%A7%A3%E7%90%86%E6%83%B3%E5%B0%8F%E9%B9%8F%E8%94%9A%E6%9D%A5%E7%9A%84%E6%8A%80%E6%9C%AF%E5%88%86%E6%B0%B4%E5%B2%AD/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      城市NOA功能竞品分析
    </h1>
    <div class="post-meta"><span title='2025-07-23 00:00:00 +0000 UTC'>July 23, 2025</span>

</div>
  </header> 
  <div class="post-content"><h1 id="城市noa技术战局上从bev到vla拆解头部玩家技术路线">城市NOA技术战局（上）：从BEV到VLA，拆解头部玩家技术路线<a hidden class="anchor" aria-hidden="true" href="#城市noa技术战局上从bev到vla拆解头部玩家技术路线">#</a></h1>
<p><strong>主要结论：</strong></p>
<p>继2023–2024年BEV+Transformer+Occupancy Network架构成为智能驾驶的感知主流后，2025年起，行业正加速向更高级的**VLM（Vision-Language Model）<strong>与</strong>VLA（Vision-Language-Action）**模型演进。相较于传统BEV结构仅关注空间几何关系，VLM/VLA引入语言推理模块，可对标志、规则、指令进行语义理解，结合多模态输入（如摄像头图像、语音交互、交通文本信息），生成更泛化、更类人的行为决策。</p>
<p>芯片与算力能力成为支撑城市NOA架构升级的关键基础。2020年前后主流平台算力集中于144 TOPS，如今已普遍跃升至500 TOPS以上，高端平台如蔚来NX9031、理想Thor-U、小鹏图灵AI芯片等更达到千级算力，支撑端到端推理、大模型部署与多模态处理。自研芯片、自建智算中心、自主模型训练正成为具备战略自主能力车企的核心壁垒。</p>
<p>在感知侧，“视觉为主+激光雷达补盲”已成为当前主流配置。视觉方案具备数据规模与算力适配优势，激光雷达则增强空间精度与安全冗余，尤其在无高精地图场景中具备更强稳定性。不同厂商依据策略选择单感知或多模态融合方案，构建安全容错体系。</p>
<ol>
<li><strong>产品背景</strong></li>
</ol>
<p>近年来，随着特斯拉AutoPilot不断进阶至FSD，辅助驾驶已从L0级定速巡航，逐步拓展至高速NOA，再迈入城市NOA阶段，覆盖更复杂多变的交通环境。智能驾驶正在从“技术亮点”转向“核心卖点”，显著影响消费者购车决策。</p>
<p>以小鹏和问界为例：小鹏G6智驾版配置占比超过70%，问界新M7的大定用户中也有60%以上选择搭载高阶智能驾驶方案。这一趋势标志着，中国智能驾驶市场已全面进入L2+/NOA功能的规模化普及阶段。</p>
<p>L2+辅助驾驶能力包括自适应巡航（ACC）、车道居中控制（LCC）、自动变道（ALC）、高速NOA等，城市NOA则在此基础上，扩展至非结构化路况中的红绿灯通行、环岛绕行、路口博弈等复杂决策工况，对感知精度、决策智能与系统泛化能力提出更高要求。</p>
<p>在城市NOA推进过程中，<strong>高精地图鲜度不足、覆盖受限、成本高昂等问题，成为核心瓶颈</strong>。为突破此限制，主流技术路线正在从依赖地图的规则驱动方案，全面转向<strong>端到端模型驱动 + 自主环境建图 + 多模态策略融合</strong>的新范式。</p>
<p>技术架构上，感知模块经历了从前向2D视角 → BEV建图 → Occupancy Network建模的迭代，决策控制模块也正由传统rule-based状态机，向<strong>基于神经网络的端到端行为预测</strong>发展。2025年起，VLM（视觉语言模型）和VLA（Vision-Language-Action）架构逐步上车，赋予系统语义理解与策略推理能力，成为当前算法演进的前沿方向。</p>
<p>本报告将围绕特斯拉、小鹏、理想、蔚来等具备自研能力的头部品牌，梳理其城市NOA技术路线演进路径，结合软硬件系统方案与市场落地节奏，探讨中国品牌如何在“从BEV到VLA”的产业跃迁中建立领先优势。</p>
<ol start="2">
<li><strong>目标用户与使用场景</strong></li>
</ol>
<p>L2/L2+辅助驾驶系统主要面向具备一定驾驶经验、希望在日常通勤或长途驾驶中降低疲劳、提升安全性的新能源车主及购车潜在用户。</p>
<p>这类用户普遍关注两个关键问题：</p>
<p>各品牌城市NOA在不同城市、路况下的表现差异；</p>
<p>智驾能力与整车价格之间的性价比。</p>
<p>智能驾驶的核心价值在于：在用户监管下，系统能够预判潜在风险、辅助完成复杂驾驶动作，从而减轻认知负担、降低事故风险。尤其在城市NOA场景中，系统需完成红绿灯识别、路口博弈、避让行人、自主换道等行为，对系统泛化能力、策略鲁棒性和人机交互体验提出更高要求。</p>
<p>因此，城市NOA不仅是“功能拓展”，更代表了整车系统智能化水平的“天花板”。</p>
<ol start="3">
<li><strong>竞品分析</strong></li>
</ol>
<p>本篇章节主要对于特斯拉，以蔚来理想小鹏为代表的头部企业在“城市导航辅助驾驶功能”的进展上进行对比分析，除此之外还包括，硬件系统方案，软件算法，功能配置，交互逻辑，运营方案，亮点场景等对比。</p>
<p><strong>3.1 调研洞察摘要</strong></p>
<p>城市NOA的落地，标志着行业正从规则驱动向数据驱动、从模块化架构向端到端大模型架构转变。以下趋势尤为明显：</p>
<p><strong>技术架构趋同：</strong> 特斯拉、小鹏、蔚来等主流厂商均采用BEV+Transformer+Occupancy Network感知结构，逐步引入端到端神经网络控制器替代传统状态机，提升整体智驾稳定性。</p>
<p><strong>算力平台升级：</strong> 主流平台从原先144TOPS提升至500–1000TOPS以上，大算力平台成为支持端到端大模型部署的基础设施。</p>
<p><strong>数据闭环能力强化：</strong> 具备自动采集、筛选、标注、仿真重建与在线训练能力的“数据-模型-闭环”体系，成为城市NOA性能提升的核心引擎。</p>
<p><strong>用户体验导向增强：</strong> 城市NOA正加速从试点区域向全国多城落地，主机厂纷纷围绕“全国都能开、用户真愿用”目标，推动功能迭代与大模型泛化能力提升。</p>
<p>结论：<strong>在城市NOA成为新一代智能驾驶标配的背景下，能否构建“低成本、高泛化、大闭环”的自研体系，将成为厂商能否突围的核心分水岭。</strong></p>
<p><strong>3.2 技术方案演进与“去高精地图化”</strong></p>
<p>高速NOA因场景结构稳定，长期采用规则驱动+高精地图方式实现；而城市NOA因存在海量动态变量与非结构化场景，传统Rule-based方案难以覆盖，<strong>技术路线普遍演进为以下三个阶段：</strong></p>
<p><strong>基于高精地图的三段式结构：</strong> 感知–规划–控制，依赖静态地图与有限状态机；</p>
<p><strong>BEV+Transformer感知融合结构：</strong> 引入Occupancy Network构建3D空间占据图，提升遮挡处理与障碍识别能力；</p>
<p><strong>端到端 + 多模态语义推理架构（VLA）：</strong> 引入视觉语言模型、扩散策略网络、博弈推理模块等，实现感知–理解–决策一体化。</p>
<p>“去高精地图化”已成为城市NOA发展的行业共识，各家方案通过Occupancy Network、弱地图辅助、分布式建图等方式逐步替代静态地图依赖，以提升系统泛化能力与落地效率。</p>
<p><strong>3.2.1 特斯拉技术演进：</strong></p>
<p><img loading="lazy" src="/images/NOA_image1.png"></p>
<p>自2014年发布AutoPilot 1.0以来，特斯拉持续引领辅助驾驶从规则驱动走向数据驱动、再走向端到端神经控制的范式演进。</p>
<p><strong>HW1.0 + Mobileye平台（2014–2016）：</strong> 初代AutoPilot基于Mobileye方案，支持基本的巡航与车道保持功能，但受限于单摄像头配置与规则逻辑，系统泛化能力有限。</p>
<p><strong>HW2.0/2.5 + Drive PX2（2016–2018）：</strong> 特斯拉转向自研算法，采用8摄像头+12雷达传感器+NVIDIA PX2平台，基于FSM（有限状态机）实现早期的高速NOA能力（Navigate on AutoPilot Beta）。</p>
<p><strong>HW3.0 + 自研FSD芯片（2019–2020）：</strong> 发布自研AI芯片并正式推出FSD Beta内测计划，引入EAP（增强版辅助驾驶）并释放自动变道功能。感知层构建多模态融合机制，识别红绿灯、停车标志等交通要素。</p>
<p><strong>2021年 AI Day：引入BEV + Transformer：</strong> 特斯拉提出基于多摄像头拼接构建的BEV（Bird&rsquo;s Eye View）语义空间，并通过Transformer提取时空依赖关系，实现更强遮挡推理与路径预测能力，标志着系统感知结构全面转向空间+时间理解。</p>
<p><strong>2022–2023年 Occupancy Network 推出：</strong> 引入3D空间占据网络，用于替代静态物体语义分割，提升空间几何精度与实时性，为去地图化打下基础。部署于FSD Beta v11系列中，支持城市NOA的全面扩展。</p>
<p><strong>2023年末发布FSD v12：</strong> 正式上线端到端神经控制器，感知直接映射至转向、加速、刹车动作，彻底取代规划与控制模块。这一升级意味着智能驾驶真正进入**“One Model”时代**，也标志着行业从模块化向认知驱动模型全面转型。</p>
<p><strong>HW4.0平台（2023+）：</strong> 在部分车型上部署高分辨摄像头与毫米波雷达（激光雷达仅用于Dojo训练），进一步提升全场景感知能力，为FSD大模型的推理提供硬件支撑。</p>
<p><strong>AI5平台与FSD v13（2025预期）：</strong> 计划搭载全新FSD芯片，算力提升至2500 TOPS，具备训练+推理一体能力，为多模态VLA结构运行提供充足支撑。</p>
<p>2D BEV</p>
<p><img loading="lazy" src="/images/NOA_image2.png"></p>
<p>3D Occupancy map</p>
<p><img loading="lazy" src="/images/NOA_image3.png"></p>
<p>综上，特斯拉的NOA从2014年AutoPilot 1.0起，经历了从<strong>规则驱动（FSM）阶段 → 模块化感知融合阶段 → 纯视觉阶段 → BEV+Transformer阶段 → 端到端控制阶段</strong>的五轮迭代，逐步完成从高速NOA向城市NOA的跨越。</p>
<p>特斯拉率先实现了从外部平台（Mobileye、NVIDIA）向自研芯片（FSD）转型，从依赖高精地图向Occupancy构图演进，并通过BEV+Transformer结构突破传统感知瓶颈；自FSD Beta v12起，正式引入<strong>端到端神经网络控制器</strong>，实现由感知直接输出动作信号（转向角、加速度、电机扭矩等），彻底摆脱规则和状态机。</p>
<p>在硬件层面，特斯拉于2023年推出HW4.0平台，新增高精毫米波雷达并强化摄像头体系，算力预计达500–600 TOPS；其AI5平台预计2025年问世，配备下一代FSD芯片，算力或达2500 TOPS，支撑大模型与复杂推理需求。</p>
<p>这一路径不仅体现出特斯拉作为“智驾大模型先行者”的技术先发优势，也为中国品牌提供了路径参照：<strong>即通过芯片+算法+数据的全栈闭环，率先完成去高精地图化、端到端控制闭环与全场景泛化能力</strong>。</p>
<p><strong>3.2.2 小鹏技术演进：</strong></p>
<p><img loading="lazy" src="/images/NOA_image4.png"></p>
<p><strong>小鹏城市NOA技术演进路径（时间轴）</strong></p>
<p><strong>2018年</strong>：发布 <strong>Xpilot 2.0</strong>，定位“智能化先锋”，初代功能包括：</p>
<p>自适应巡航（ACC）</p>
<p>车道保持辅助（LKA）</p>
<p><strong>2019年起</strong>：通过 <strong>OTA 升级为 Xpilot 2.5</strong>，实现辅助功能初步融合：</p>
<p>泊车辅助功能上线</p>
<p>城市驾驶辅助能力如：</p>
<p>交通拥堵辅助（TJA）</p>
<p>自动变道辅助（ALC）</p>
<p>高速NOA与城市辅助功能初步结合</p>
<p><strong>2021年</strong>：升级为 <strong>Xpilot 3.5 / NGP（Navigation Guided Pilot）</strong>：</p>
<p>开启城市导航辅助驾驶（NGP）的小范围测试</p>
<p>结合用户反馈不断迭代软件版本</p>
<p><strong>2022年</strong>：推出 <strong>XNet 感知架构</strong>：</p>
<p>BEV+Transformer 感知方案</p>
<p>无需依赖高精地图即可构建 <strong>3D语义场景</strong></p>
<p>硬件平台升级为：</p>
<p><strong>双Orin-X芯片</strong></p>
<p><strong>双激光雷达</strong>支持，提升感知精度与算力冗余</p>
<p><strong>2023年</strong>：正式发布 <strong>XNGP Beta版</strong>，进入“全场景无图辅助驾驶”落地元年：</p>
<p><strong>XNet 2.0</strong>：融合多模态传感器（摄像头、激光雷达、IMU）</p>
<p>使用Transformer提取高语义特征</p>
<p>构建动态3D Occupancy地图</p>
<p>替代传统高精地图部分功能</p>
<p>路径规划模块升级为 <strong>XPlanner</strong> 大模型规划器：</p>
<p>强泛化能力</p>
<p>高速推理性能</p>
<p>更适应复杂城市场景的动态决策需求</p>
<p>小鹏进一步通过端到端大模型结构提升泛化能力，持续从海量真实路况数据中学习驾驶策略，并借助城市级仿真平台生成corner case进行模型鲁棒性训练。到2024年，小鹏XNGP已实现对全国绝大多数城市的“无图化泛化部署”，形成产品认知“全国都好用”，构筑品牌差异化优势。</p>
<p>总体来看，小鹏通过“架构+数据+算力”的持续进化，构建了“BEV+大模型+无图化”的完整闭环，其路线呈现出从规则与地图依赖 → 感知结构自研 → 大模型推理 → 真正泛化能力释放的典型国产突破范式，成为城市NOA赛道的技术破局者之一。</p>
<hr>
<p><strong>3.2.3 理想技术路线：</strong></p>
<p><img loading="lazy" src="/images/NOA_image5.png"></p>
<p>理想智能驾驶整体技术路线遵循“<strong>功能迭代 → 感知进化 → 架构升级</strong>”三阶段策略，逐步实现从传统L2辅助驾驶到城市NOA，再向通用智能体系统过渡。</p>
<p><strong>阶段一：功能迭代（2019–2022）</strong></p>
<p>自2019年发布首代L2功能（LDW、LCA、ACC等）起，理想逐步构建自动驾驶基础能力。2021年推出AD 1.0，实现高速NOA，支持变道辅助、上下匝道等典型操作。2022年发布AD Max 2.0，引入双Orin-X芯片与双激光雷达，为城市NOA感知能力拓展提供基础。</p>
<p><strong>阶段二：感知进化（2023）</strong></p>
<p>2023年理想发布AD Max 3.0，标志城市NOA基于高精地图方案正式全国推送。同时引入多模态感知、融合视觉/雷达/激光数据，以及占用网络技术，提升障碍物识别与动态建图能力，应对城市复杂场景。</p>
<p><strong>阶段三：架构升级（2024–2025）</strong></p>
<p>理想进入“<strong>无图NOA</strong> + <strong>快慢系统融合</strong>”时代：</p>
<p><strong>快系统</strong>使用轻量化端到端模型（One Model）处理常见驾驶场景，具备前馈控制与实时响应能力；</p>
<p><strong>慢系统</strong>引入视觉语言大模型（VLM），可理解多模态输入（图像+语音），用于处理复杂/边缘工况与策略生成。两者协同，实现大脑“直觉+思考”的联动机制。</p>
<p>2025年，理想推出新一代<strong>VLA智能体架构</strong>，融合“3D编码感知+语言推理+策略生成器”三大模块，具备“<strong>听得懂、看得见、找得到</strong>”的泛化能力。驾驶员一句语音“靠边停车”，系统可实时理解意图、分析周边场景、生成目标路径，实现从感知到控制的统一闭环。</p>
<p>总体而言，理想的城市NOA路线呈现出从规则驱动 → 感知增强 → 多模态大模型 → 泛化智能体的进化曲线，是国内智能驾驶架构升级路径中最具“认知理解+语义泛化”特色的代表之一。</p>
<hr>
<p><strong>3.2.4 蔚来技术路线：</strong></p>
<p><img loading="lazy" src="/images/NOA_image6.png"></p>
<p><strong>蔚来城市 NOA 推进路径</strong></p>
<p><strong>2017年12月</strong>：发布 <strong>NIO Pilot</strong>，依赖 Mobileye EyeQ4 芯片，支持高速NOA起步。</p>
<p><strong>2020年10月</strong>：推出 <strong>NOP Pilot</strong> 升级版本，加入自适应巡航、车道保持、车道偏离辅助等核心能力。</p>
<p><strong>2022年3月</strong>：搭载NT2平台车型，发布自研 <strong>NAD系统</strong>，包括：</p>
<p>33个传感器组成的 <strong>Aquila硬件平台</strong></p>
<p>4颗Orin芯片组成的 <strong>Adam超算平台</strong></p>
<p>推出 <strong>NOP+</strong> 功能，正式进入城市道路辅助驾驶阶段。</p>
<p><strong>2023年6月</strong>：城市NOA功能开启小范围用户开放测试，初步具备：</p>
<p>红绿灯识别</p>
<p>环岛通行处理</p>
<p>城市路口的动态障碍绕行与路径选择</p>
<p><strong>2024年</strong>：发布 <strong>NAD增强版本</strong>，技术演进包括：</p>
<p>引入 <strong>BEV感知融合模块</strong></p>
<p>引入 <strong>Transformer预测模型</strong></p>
<p>城市NOA能力拓展至更多 <strong>一线/二线城市</strong></p>
<p><strong>2025年起</strong>：计划正式部署 <strong>点到点无图导航（Point-to-Point NO Map Navigation）</strong></p>
<p>支持城区NOA的全国范围落地与无图部署</p>
<p><strong>世界模型NWM：通向L3/L4的认知闭环核心</strong></p>
<p>蔚来构建了名为 <strong>NWM（NIO World Model）</strong> 的通用环境建模系统。其本质是一个基于 <strong>BEV语义建图 + Occupancy网络 + Transformer推理</strong> 的<strong>统一语义空间</strong>，旨在支持车辆对环境的三维建模、时空预测与语义理解，突破地图依赖限制，增强泛化部署能力。</p>
<p>该模型不仅整合感知→建图→预测三大环节，还能够从多源数据中生成策略输入。蔚来强调通过<strong>真实驾驶数据+生成式仿真+三维重建</strong>构建训练场景，并不断优化世界模型泛化能力，形成“端到端+模块调度+语义空间推理”的融合能力。</p>
<p><strong>技术趋势：从重地图→重感知→重建模，向大模型统一架构演进</strong></p>
<p>蔚来当前的系统正加速从高精地图依赖，向轻地图+重感知演进，核心架构逐步向端到端靠拢，同时保留模块间的可控边界与冗余机制。这一策略与小鹏（BEV融合 + OCC预测）与理想（快慢系统协同）形成差异化：蔚来更强调**“构建环境语义空间”**，将城市感知、动态建图、行为生成纳入统一大模型框架。</p>
<p><strong>3.3 硬件系统对比：从硬件堆叠走向芯片-模型协同</strong></p>
<p>随着城市NOA进入无图化与泛化部署阶段，主机厂正在由“堆叠式硬件架构”迈向“芯片-模型协同优化”的路线。高算力、低功耗、平台集成度以及对大模型的适配能力，正成为智能驾驶核心硬件系统的关键评价标准。</p>
<p><strong>多模态传感器逐渐标配，感知覆盖从静态拓展到动态全场景理解，激光雷达价格持续下探。</strong></p>
<p><strong>AI大模型驱动芯片需求跃迁，自研SoC成为整车厂构建智驾护城河的重要路径。</strong></p>
<p><strong>3.3.1 主流厂商芯片与算力平台对比</strong></p>
<p><strong>特斯拉 Tesla</strong></p>
<p>使用 <strong>HW4.0平台 + 自研FSD芯片（FSD Chip v2）</strong>，不再依赖激光雷达，采用：</p>
<p>8 颗摄像头 + 1 毫米波雷达（2023年起重新引入）</p>
<p>算力约 500–600 TOPS，支撑纯视觉城区NOA能力（基于 Occupancy Network 和 BEV 结构）</p>
<p>FSD Beta 城市NOA已在北美广泛部署，算力和能效比行业领先。</p>
<p><strong>蔚来 NIO</strong></p>
<p>智驾系统演进路线：Orin X（ET7/ES7） → 自研 NX9031（ET9）</p>
<p><strong>ET7</strong>：搭载 4 颗 NVIDIA Orin-X，整车算力 1016 TOPS</p>
<p><strong>ET9</strong>：全球首款上车自研大算力芯片 <strong>NX9031（“神玑”）</strong>，专为大模型语义推理优化，支持运行 NWM 世界模型（支持时空建图 + 策略决策解耦）</p>
<p>感知系统构成：</p>
<p>“Aquila超感系统”：33 个传感器节点，含 3 广角摄像头、1 主摄、1 激光雷达、5 毫米波雷达、12 超声波雷达等</p>
<p>具备“软硬协同、模型驱动”的系统闭环特征，面向L3能力演进。</p>
<p><strong>理想 Li Auto</strong></p>
<p>原平台为 2 颗 NVIDIA Orin-X，508 TOPS（如L9、L8）</p>
<p>最新 Max 系列车型上，已切换至 <strong>Thor-U 芯片（700 TOPS）</strong>，为 L3 设计预留算力空间</p>
<p>推出端到端视觉语义架构（VLM/VLA），强调统一模型适配“感知-理解-行为”链路</p>
<p>公布规划：<strong>2025年起全系标配激光雷达</strong>，以增强感知精度与冗余能力</p>
<p><strong>小鹏 XPeng</strong></p>
<p>芯片演进路径：EyeQ4（Xpilot 2.5）→ Xavier（Xpilot 3.0）→ Orin-X（Xpilot 4.0/XNGP）</p>
<p>当前主力平台为：<strong>2颗 Orin-X，508 TOPS</strong></p>
<p>搭载 13 摄像头 + 激光雷达 + 毫米波雷达，支撑无图城市NOA部署</p>
<p>推出自研计算平台：<strong>XCCP 中央计算平台（XEEA 3.5）</strong></p>
<p>架构集成智驾、座舱、车控网关等多个域</p>
<p>实现 <strong>硬件成本下降40%，整车算力利用率提升50%</strong></p>
<p><img loading="lazy" src="/images/NOA_image7.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>3.3.2 自研芯片进展：从硬件堆叠走向“芯片+模型”深度耦合</strong></p>
<p><strong>行业趋势</strong>：</p>
<p>高算力芯片 + 自研大模型 + 云边端协同训练，成为智能驾驶系统核心能力的构建基础；</p>
<p>高端通用芯片（如Orin-X）成本高企，推动主机厂自研以控制成本并优化模型运行效率；</p>
<p>自研芯片可实现更高能效比与对模型结构的精细适配。</p>
<p><strong>一.芯片自研更好适配自研算法</strong></p>
<p><strong>蔚来 NIO</strong></p>
<p>上车芯片：自研 <strong>神玑 NX9031</strong></p>
<p>应用车型：ET9、新ES6、EC6、ET5T</p>
<p>技术亮点：单颗算力 ≈ 4×Orin-X，支持 NWM 世界模型运行，具备高功能安全等级与优秀功耗控制</p>
<p>战略价值：已初步达成“整车厂芯片自研”战略落地目标</p>
<p><strong>小鹏 XPeng</strong></p>
<p>上车芯片：自研 <strong>图灵 AI 芯片</strong></p>
<p>应用车型：G7（首款AI架构车）</p>
<p>架构特色：搭载 <strong>3颗图灵芯片</strong>，可同时运行智驾+座舱双大模型（VLA + VLM）</p>
<p>实际算力：有效算力约 <strong>2200 TOPS</strong>，约等于9颗传统智驾芯片</p>
<p><strong>理想 Li Auto</strong></p>
<p>当前进展：已量产自研 <strong>碳化硅功率芯片</strong>，正在推进智能驾驶芯片开发</p>
<p>目标架构：适配端到端+大模型架构，强化整车算力闭环能力</p>
<p><strong>特斯拉 Tesla</strong></p>
<p>芯片平台：<strong>FSD Chip V2</strong>（自研），搭配 HW4.0 硬件系统</p>
<p>技术特色：纯视觉感知架构支撑 Occupancy Network，无需激光雷达</p>
<p>上车效果：已支撑北美城区NOA大规模部署，能效比行业领先</p>
<p><strong>二、自建智算中心：训练提速、数据闭环打通</strong></p>
<p><strong>建设趋势</strong></p>
<p>面向 PB 级数据的模型训练需求激增，推动主机厂加速构建“自建智算中心”；</p>
<p>智算中心成为大模型训练效率与数据闭环速度的决定性因素。</p>
<p><strong>小鹏 XPeng</strong></p>
<p>智算中心名称：<strong>扶摇</strong></p>
<p>合作伙伴：阿里云</p>
<p>建设位置：乌兰察布（2022年建成）</p>
<p>峰值算力：<strong>600 PFLOPS</strong></p>
<p>成果：核心模型训练周期从 7 天缩短至 1 小时，提升近 170 倍</p>
<p><strong>理想 Li Auto</strong></p>
<p>云端算力储备：<strong>4.5 EFlops</strong></p>
<p>正联合火山引擎在山西布局智算中心，支持端到端大模型训练</p>
<p>构建覆盖车端-边缘-云端的训练闭环体系</p>
<p><strong>蔚来 NIO</strong></p>
<p>云端训练系统支持 <strong>百倍于车端模型规模的无监督大模型训练</strong></p>
<p>训练数据无需标注，聚焦 PB 级数据处理能力，适配世界模型推理任务</p>
<p><strong>特斯拉 Tesla</strong></p>
<p>智算平台：<strong>Dojo 超级计算机</strong></p>
<p>预计 2024 年完成部署，峰值算力目标 <strong>100 EFLOPS</strong></p>
<p>专为端到端模型 Occupancy Network 优化训练路径</p>
<p><strong>厂商布局概览</strong>：</p>
<p><img loading="lazy" src="/images/NOA_image8.png"></p>
<p><strong>3.4 功能配置对比分析：基础趋同，高阶分化</strong></p>
<p>功能配置上，主流品牌基础智驾配置趋于同质化，</p>
<p><strong>一、基础功能全面覆盖，主流车型已同质化</strong></p>
<p><strong>中高端电动车基础智驾功能高度一致化</strong>：</p>
<p>主流标配功能：<strong>ACC（自适应巡航）、LCC（车道居中）、APA（自动泊车）、PDC（前后泊车雷达）、FCW（前向碰撞预警）、BSD（盲区监测）、RCTA（后方横向来车预警）</strong></p>
<p>这些功能构成智能驾驶入门级配置，已成为20万以上主流车型“标配底线”</p>
<p>** 二、C-NOA 城市领航辅助：标配化趋势明显</p>
<blockquote>
</blockquote>
<p>随着大模型感知与规划能力提升，<strong>城市NOA（C-NOA）正在成为智能车型的主流卖点</strong>；</p>
<p>各大厂商（小鹏、理想、蔚来等）已将其作为产品“卖点功能”标配；</p>
<p>依赖大模型能力（如BEV+Transformer/Occupancy Network）+高精定位/建图</p>
<p>** 三、高速NOA：20万级以上车型标配，高阶能力差异化</p>
<blockquote>
</blockquote>
<p><strong>高速NOA功能已基本覆盖中高端智能电动车</strong>，是“上车的门槛功能”；</p>
<p>多数品牌实现：导航路径自动变道、匝道进出、自动上下匝道等；</p>
<p>但在<strong>匝道识别准确率、拥堵跟车体验</strong>等方面存在感知模型差异</p>
<p><img loading="lazy" src="/images/NOA_image9.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p>√‑：带有该功能的基础版本</p>
<p>√ ： 带有该功能</p>
<p>—：不带有该功能</p>
<p><strong>四、主动安全：感知全面、控制策略分化明显</strong></p>
<p><strong>感知类主动安全功能趋于全覆盖</strong>：</p>
<p>BSD（盲区监测）、RCW（后向碰撞预警）、TSR（交通标志识别）等均已普及；</p>
<p><strong>控制干预类功能存在明显差异</strong>：</p>
<ul>
<li>*AES（主动紧急转向）、FCTB（前向碰撞主动制动）**等高级主动干预功能：</li>
</ul>
<p>仅<strong>理想L9、蔚来ET7</strong>等高端车型支持；</p>
<p>显示出控制策略算法和车辆控制器能力的差异</p>
<p><img loading="lazy" src="/images/NOA_image10.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>五、泊车能力：从APA向RPA/VPA/HPA进化</strong></p>
<p>各厂商智能泊车能力向更高级别进化：</p>
<p><strong>RPA（遥控泊车）</strong>：用户在车外通过手机控制泊车</p>
<p><strong>VPA（记忆泊车）</strong>：可自动记忆和回放特定路径停车</p>
<p><strong>HPA（代客泊车）</strong>：自主寻找并泊入车位（仍在迭代中）</p>
<p><strong>理想、小鹏部署最完整</strong>，已逐步实现量产落地</p>
<p><strong>六、特斯拉在中国市场主动安全能力相对保守</strong></p>
<p>中国版特斯拉在主动安全功能上较为谨慎配置：</p>
<p><strong>更多依赖被动安全机制（气囊/结构）与驾驶提醒机制</strong>；</p>
<p>缺乏本地化的细粒度控制策略（如自动避障、车道强制保持）</p>
<p><strong>3.5 软件算法演进趋势与品牌对比</strong></p>
<p><strong>行业算法架构演进：从模块式到端到端</strong></p>
<p>当前主流技术路线逐步经历以下几个阶段，逐步向“纯视觉 + 大模型 + 全端到端”演进：</p>
<hr>
<p><img loading="lazy" src="/images/NOA_image11.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>总结</strong></p>
<p>：各家厂商当前多处于</p>
<p><strong>阶段3（特征级融合）</strong></p>
<p>向</p>
<p><strong>阶段4（控制级E2E）</strong></p>
<p>过渡的阶段。特斯拉、理想、小鹏走在前列。</p>
<hr>
<p><strong>3.5.1 特斯拉算法演进路径（2018–2025）</strong></p>
<p><strong>🔹 第一阶段（2018–2020）：传统三段式 + 高精地图</strong></p>
<p>感知：依赖摄像头 + 毫米波雷达识别静态语义；</p>
<p>规划：结合高精地图和有限状态机判断行为；</p>
<p>控制：指令执行模块；</p>
<p>特点：架构稳定，地图依赖重，主要应用于高速NOA。</p>
<p><strong>🔹 第二阶段（2020–2022）：BEV + Transformer 感知架构</strong></p>
<p>多摄像头纯视觉，构建<strong>统一BEV语义空间</strong>；</p>
<p>Transformer整合时序，建模完整场景；</p>
<p>去地图化进程启动，为更广泛的泛化能力做准备。</p>
<p><strong>🔹 第三阶段（2022–2025）：Occupancy Network + E2E 控制器</strong></p>
<p>Occupancy 网络实现<strong>动态连续空间建模</strong>，不再依赖明确物体边界；</p>
<p>引入高精毫米波雷达增强可用性；</p>
<p>FSD v12/13 引入 <strong>E2E控制器</strong>，直接输出方向盘与踏板指令；</p>
<p>真正实现“感知→控制”一体化神经网络闭环。</p>
<p><strong>特斯拉数据闭环系统能力</strong></p>
<p>自2022年起，特斯拉构建出完整的数据驱动闭环体系，是其E2E算法快速演进的核心支撑。</p>
<hr>
<p>车辆端：大规模车主实车采集（百万量级）；</p>
<p>云端：Dojo集群用于高频模型迭代；</p>
<p>工具链：自动标注、数据筛选系统，提升数据效率；</p>
<p>仿真端：策略补强用极端/罕见场景仿真生成并参与训练。</p>
<p><strong>3.5.2 小鹏：从规则逻辑到全场景大模型</strong></p>
<p>小鹏自动驾驶系统从 Xpilot 到 XNGP，完成了从规则逻辑 → 感知驱动 → 大模型驱动的三阶段演进，技术架构逐步升级为端到端BEV+Transformer+Occupancy体系，全面摆脱高精地图依赖：</p>
<p><strong>阶段一：Xpilot 2.x（规则逻辑 + 高精地图）</strong></p>
<p><strong>时间节点</strong>：2019年发布 Xpilot 2.5</p>
<p><strong>典型功能</strong>：ACC自适应巡航、LCC车道居中、自动变道辅助</p>
<p><strong>技术架构</strong>：</p>
<p>三段式“感知–规划–控制”架构</p>
<p>决策规划依赖高精地图与状态机控制</p>
<p>场景泛化能力有限，主要覆盖高速场景</p>
<p><strong>阶段二：Xpilot 3.x（NGP → 感知增强 + 导航融合）</strong></p>
<p><strong>优化方向</strong>：提升感知精度，引入导航路径作为软决策依据</p>
<p><strong>技术特点</strong>：</p>
<p>感知仍以规则逻辑为主，部分场景由状态机管理</p>
<p>引入动态导航线用于路径引导</p>
<p><strong>限制问题</strong>：依然高度依赖高精地图，泛化能力不足，难以覆盖复杂城市场景</p>
<p><strong>阶段三：XNGP（BEV + Transformer + Occupancy + 大模型）</strong></p>
<p><strong>发布时间</strong>：2023年</p>
<p><strong>核心特征</strong>：全场景无图、端到端语义决策架构</p>
<p><strong>技术组成</strong>：</p>
<p><img loading="lazy" src="/images/NOA_image12.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>Occupancy Network</strong>：</p>
<p>替代传统语义分割</p>
<p>提升空间建模的连贯性与遮挡场景推理能力</p>
<p><strong>架构转型</strong>：</p>
<p>从“感知–规划–控制”三段式 → “感知–预测–控制”端到端</p>
<p><strong>彻底脱离高精地图</strong>，依赖视觉语义空间引导行为与路径</p>
<p><img loading="lazy" src="/images/NOA_image13.png"></p>
<p><strong>3.5.3 蔚来技术演进</strong></p>
<p>蔚来的自动驾驶系统沿着“从规则到学习驱动”、“从依赖地图到感知建图”的方向演进，逐步构建出具备<strong>世界建模能力与交互式行为推理能力</strong>的高阶智能驾驶系统。整体架构可支持高精地图与纯感知双模切换，并通过“群体智能+世界模型”的端云协同方式持续迭代与泛化。</p>
<p><strong>一. 架构演进路径</strong></p>
<p><strong>算法框架：</strong> 从 rule-based 的 NOP，演进为数据驱动、端到端分段学习的世界模型 NWM（NIO World Model）；</p>
<p><strong>感知演进：</strong> 从单帧感知 → 多帧 BEV 表征 → 时序 Transformer 网络结构；</p>
<p><strong>地图依赖：</strong> 从高精地图导航 → Occupancy 网络实时构图 → 支持“无图城区 NOA”；</p>
<p><strong>规划策略：</strong> 从 NOP 的状态机路径规划 → NAD 的交互搜索 + 拟人博弈优化决策。</p>
<p><strong>二. 感知与建图模块：NAD Lane 2.0 + Occupancy Network</strong></p>
<p>蔚来在感知端采用 BEV + Transformer 结构的 NAD Lane 2.0 网络，结合前向多帧信息处理，适应城区复杂语义环境。同时引入 Occupancy 网络用于构建动态场景占据图，摆脱对静态高精地图的依赖。</p>
<p><strong>感知模型输出：</strong></p>
<p>动态 Occupancy Grid；</p>
<p>多类别语义分割；</p>
<p>精确定位的时空障碍物。</p>
<p>这些输出作为输入，传递给世界模型与行为规划模块，构成“端上世界建模”的基础。</p>
<p><strong>三. 规划与控制链路：三层分层结构 + 博弈推演</strong></p>
<p>为应对城市场景中的高复杂性与解空间爆炸问题，蔚来提出“全链路学习式的分层行为推理结构”：</p>
<p><strong>第一层：多模态注意力网络</strong></p>
<p>输入 Occupancy、语义地图、历史轨迹；</p>
<p>输出 Top-K（如10~100）个可行动作序列（候选轨迹）。</p>
<p><strong>第二层：交互式搜索树（7秒/步）</strong></p>
<p>以每秒为一阶段，模拟 7 秒的交互行为；</p>
<p>同时建模自车与他车的反应过程，实现行为博弈。</p>
<p><strong>第三层：价值博弈网络（GAM）</strong></p>
<p>对搜索树中的候选轨迹进行价值排序；</p>
<p>考虑“安全-舒适-效率”平衡，选出最拟人化的行为。</p>
<p><strong>兜底控制：凸优化解算器</strong></p>
<p>将轨迹输出转化为可执行控制信号，保证安全约束与鲁棒性。</p>
<p>该结构实现了从多模态信息 → 多轨迹推演 → 博弈评分 → 优化控制的完整闭环，相比早期规划方法，在城区 cut-in 场景中提升了约 <strong>30% 的驾驶安全性</strong>。</p>
<p><strong>四. 世界模型部署与训练机制</strong></p>
<p>蔚来的世界模型 NWM 已部署于 Banyan 平台的二代车型上，具备“场景理解+想象重建+推演预测”的能力，支持端侧运行。模型具备以下关键能力：</p>
<p>想象建图（imaginative reconstruction）；</p>
<p>多目标轨迹预测（multi-agent simulation）；</p>
<p>拟人行为推理（human-like policy reasoning）；</p>
<p>泛化到新城市、新道路场景。</p>
<p><strong>五. 群体智能与生成式仿真：数据闭环加速器</strong></p>
<p>为满足世界模型的训练需求，蔚来构建了以“群体智能 + 生成式仿真”为核心的数据闭环系统：</p>
<p><strong>群体智能采集：</strong> 通过海量用户车辆在城市路况中的行驶数据采集长尾场景；</p>
<p><strong>生成式仿真训练：</strong> 在合成环境中模拟稀有、极端场景，提升模型鲁棒性；</p>
<p><strong>世界模型微调：</strong> 将仿真轨迹与实车轨迹对齐，用于 fine-tune 端上模型。</p>
<p><strong>六. 云端算力与系统演进</strong></p>
<p>截至 2023 年 9 月，蔚来智能计算集群已达 <strong>1.4 EFLOPS</strong>；</p>
<p>2024 年 7 月，蔚来公布基于群体智能的端云总算力已超过 <strong>306.9 EOPS</strong>；</p>
<p>该能力为训练世界模型、行为博弈网络与自研大模型提供强大支撑。</p>
<p><strong>七. 商业策略与付费模式</strong></p>
<p><img loading="lazy" src="/images/NOA_image14.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>亮点场景：</strong></p>
<p>支持高速行驶中自动驶入换电站→泊入→换电→驶出→自动汇入高速，全流程无需用户接管。</p>
<hr>
<p><strong>总结：蔚来技术栈的四大特征</strong></p>
<p><img loading="lazy" src="/images/NOA_image15.png"></p>
<p><strong>点击图片可查看完整电子表格</strong></p>
<p><strong>3.5.4 理想：从分段式端到端到 MindVLA，实现高泛化能力与长尾问题覆盖</strong></p>
<p>理想的自动驾驶系统以快速迭代著称，采用“研发–量产”双线并行、滚动开发架构，在一年多时间内完成了从规则驱动到端到端+大模型的三次系统性演进：</p>
<p><strong>阶段一：规则驱动 + 高精地图</strong></p>
<p>采用传统的模块化架构，感知、定位、规划、控制各自独立部署；</p>
<p>功能依赖高精地图与状态机逻辑，NOA 已覆盖超100城；</p>
<p>泛化能力弱，复杂动态场景表现有限。</p>
<p><strong>阶段二：引入大模型，走向数据驱动</strong></p>
<p><strong>AD Max 2.0：</strong></p>
<p>感知结构升级为 BEV + Transformer；</p>
<p>核心模型：<strong>Neural Prior Network (NPN)</strong> 对 BEV 中稀疏区域进行“补全”，提升静态空间理解；</p>
<p>引入 <strong>TIN（Traffic Intention Net）</strong>，用于红绿灯意图建模与理解，增强决策可靠性。</p>
<p><strong>AD Max 3.0：</strong></p>
<p>感知端引入 <strong>Occupancy Network</strong>，用于构建实时障碍物占用图，提升对动态物体的建模能力；</p>
<p><strong>时空联合规划算法</strong> 支持避让施工、博弈变道等复杂策略；</p>
<p>启动“端到端+分模块”并行结构：</p>
<p><strong>快路径</strong>：端到端大模型直接基于传感器（摄像头+激光+毫米波）输出路径、速度等控制决策；</p>
<p><strong>慢路径</strong>：引入<strong>视觉语言模型（VLM）</strong>，通过语言解析交通标识、复杂规则，辅助快路径进行更精细判断。</p>
<p>衔接逻辑：Occupancy Network 将感知结果投影到BEV空间；端到端控制器基于 Occupancy BEV 生成低时延控制信号；VLM作为认知模块参与复杂语义信息推理与高阶决策，构成“BEV Occupancy → 快速轨迹输出 + VLM慢逻辑调节”架构。</p>
<hr>
<p><strong>阶段三：MindVLA，一体化架构跃迁，支持世界建模与博弈推理</strong></p>
<p>MindVLA（Vision-Language-Action）是一种全新的一体化通用驾驶大模型架构，目标是从数据驱动进化到认知驱动，具备场景泛化与动态博弈能力：</p>
<p><strong>Vision 模块</strong>：采用 3D 高斯空间编码器，融合多源感知（摄像头、雷达）构建 2D/3D 多粒度语义地图；</p>
<p><strong>Language 模块</strong>：基于 LLM，解析交通规则、驾驶意图、语义场景描述，通过 Chain of Thought（CoT）进行逻辑推理；</p>
<p><strong>Action 模块</strong>：融合 <strong>扩散模型（Diffusion Policy）</strong> 与 <strong>世界模型+强化学习</strong>，输出当前情境下的最优轨迹。</p>
<p>世界模型中的奖励机制不仅考虑安全与舒适，还加入了“复杂交互博弈”的回报函数，使MindVLA能在交叉口博弈、道路资源竞争、临时场景中做出“拟人化”最优决策。</p>
<hr>
<p><strong>技术亮点总结</strong></p>
<p><img loading="lazy" src="/images/NOA_image16.png"></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/tags/%E5%9F%8E%E5%B8%82noa/">城市NOA</a></li>
      <li><a href="//localhost:1313/tags/bev/">BEV</a></li>
      <li><a href="//localhost:1313/tags/occupancy-network/">Occupancy Network</a></li>
      <li><a href="//localhost:1313/tags/vla/">VLA</a></li>
      <li><a href="//localhost:1313/tags/%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">视觉语言模型</a></li>
      <li><a href="//localhost:1313/tags/%E6%99%BA%E8%83%BD%E9%A9%BE%E9%A9%B6%E6%9E%B6%E6%9E%84/">智能驾驶架构</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<script src="/js/cursor-effects.js"></script>
<script>
  new CursorEffects({
    size: 2,
    shape: 'star',
    zIndex: 9999,
  });
</script>
</body>

</html>
