<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>基于ResNet&#43;LSTM的端到端自动驾驶转向预测 | </title>
<meta name="keywords" content="CNN, LSTM, 自动驾驶, 端到端学习">
<meta name="description" content="项目背景
本项目旨在探索如何使用卷积神经网络（ResNet）提取图像空间特征，并结合LSTM对时序依赖进行建模，从而预测车辆在自动驾驶中的转向角度。
此任务属于端到端自动驾驶建模的一部分，重点在于将连续图像帧映射为连续控制输出（方向盘角度）。
模型结构概览
整体结构采用两阶段：

ResNet 特征提取：对每帧输入图像进行空间编码,提取每一帧的空间语义信息，如车道线、前车位置等。
LSTM 序列建模：将序列化的图像特征送入LSTM，实现对短期历史状态的记忆和对当前状态的连续预测,预测未来1~N帧的角度

模型结构图

数据与预处理
数据来源为模拟驾驶场景中的中心摄像头图像，标签为方向盘角度。

输入帧尺寸统一为 224x224
标签为每帧角度（可选包含扭矩、车速）
图像预处理：resize → normalize → batch
标签标准化：使用均值/方差归一化角度值
损失函数：MSE 均方误差损失
优化器：Adam, 学习率 = 1e-4
序列长度：T = 5（即每个样本为连续5帧）

实验结果
在测试集上，MSE 误差为 0.06，对应角度误差约为 7°。
模型在直线段表现稳定，在连续转弯段有一定预测延迟

关键代码片段：
class ResNetLSTMModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.resnet = resnet18(pretrained=True)
        self.lstm = nn.LSTM(input_size=512, hidden_size=128, batch_first=True)
        self.fc = nn.Linear(128, 1)

    def forward(self, x_seq):
        batch, seq_len, C, H, W = x_seq.shape
        feats = [self.resnet(x_seq[:, i]) for i in range(seq_len)]
        feats = torch.stack(feats, dim=1)  # [B, T, D]
        out, _ = self.lstm(feats)
        return self.fc(out[:, -1])
模型选择与对比分析
为什么选择 ResNet 而不是简单 CNN：">
<meta name="author" content="">
<link rel="canonical" href="//localhost:1313/posts/e2e-driving-resnet-lstm/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="//localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="//localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="//localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="//localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="//localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="//localhost:1313/posts/e2e-driving-resnet-lstm/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      基于ResNet&#43;LSTM的端到端自动驾驶转向预测
    </h1>
    <div class="post-meta"><span title='2025-04-10 00:00:00 +0000 UTC'>April 10, 2025</span>

</div>
  </header> 
  <div class="post-content"><h2 id="项目背景">项目背景<a hidden class="anchor" aria-hidden="true" href="#项目背景">#</a></h2>
<p>本项目旨在探索如何使用卷积神经网络（ResNet）提取图像空间特征，并结合LSTM对时序依赖进行建模，从而预测车辆在自动驾驶中的转向角度。</p>
<p>此任务属于端到端自动驾驶建模的一部分，重点在于将连续图像帧映射为连续控制输出（方向盘角度）。</p>
<h2 id="模型结构概览">模型结构概览<a hidden class="anchor" aria-hidden="true" href="#模型结构概览">#</a></h2>
<p>整体结构采用两阶段：</p>
<ol>
<li><strong>ResNet 特征提取</strong>：对每帧输入图像进行空间编码,提取每一帧的空间语义信息，如车道线、前车位置等。</li>
<li><strong>LSTM 序列建模</strong>：将序列化的图像特征送入LSTM，实现对短期历史状态的记忆和对当前状态的连续预测,预测未来1~N帧的角度</li>
</ol>
<h2 id="模型结构图">模型结构图<a hidden class="anchor" aria-hidden="true" href="#模型结构图">#</a></h2>
<p><img alt="模型结构" loading="lazy" src="/images/model_diagram_v2.png"></p>
<h2 id="数据与预处理">数据与预处理<a hidden class="anchor" aria-hidden="true" href="#数据与预处理">#</a></h2>
<p>数据来源为模拟驾驶场景中的中心摄像头图像，标签为方向盘角度。</p>
<ul>
<li>输入帧尺寸统一为 224x224</li>
<li>标签为每帧角度（可选包含扭矩、车速）</li>
<li>图像预处理：resize → normalize → batch</li>
<li>标签标准化：使用均值/方差归一化角度值</li>
<li>损失函数：MSE 均方误差损失</li>
<li>优化器：Adam, 学习率 = 1e-4</li>
<li>序列长度：T = 5（即每个样本为连续5帧）</li>
</ul>
<h2 id="实验结果">实验结果<a hidden class="anchor" aria-hidden="true" href="#实验结果">#</a></h2>
<p>在测试集上，MSE 误差为 <strong>0.06</strong>，对应角度误差约为 <strong>7°</strong>。<br>
模型在直线段表现稳定，在连续转弯段有一定预测延迟</p>
<p><img alt="loss_curve" loading="lazy" src="/images/loss_curve.png"></p>
<h2 id="关键代码片段">关键代码片段：<a hidden class="anchor" aria-hidden="true" href="#关键代码片段">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ResNetLSTMModel</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>resnet <span style="color:#f92672">=</span> resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTM(input_size<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>, hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>, batch_first<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x_seq):
</span></span><span style="display:flex;"><span>        batch, seq_len, C, H, W <span style="color:#f92672">=</span> x_seq<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>        feats <span style="color:#f92672">=</span> [self<span style="color:#f92672">.</span>resnet(x_seq[:, i]) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(seq_len)]
</span></span><span style="display:flex;"><span>        feats <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(feats, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)  <span style="color:#75715e"># [B, T, D]</span>
</span></span><span style="display:flex;"><span>        out, _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(feats)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>fc(out[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span></code></pre></div><h2 id="模型选择与对比分析">模型选择与对比分析<a hidden class="anchor" aria-hidden="true" href="#模型选择与对比分析">#</a></h2>
<p>为什么选择 ResNet 而不是简单 CNN：</p>
<p>预训练权重可加快收敛</p>
<p>ResNet 的残差结构对特征提取更加稳健</p>
<h2 id="为什么用-lstm-而不是-fc">为什么用 LSTM 而不是 FC：<a hidden class="anchor" aria-hidden="true" href="#为什么用-lstm-而不是-fc">#</a></h2>
<p>能捕捉时间上的上下文依赖</p>
<p>适合处理图像序列任务（比 RNN 收敛更稳定）</p>
<h2 id="我的思考">我的思考<a hidden class="anchor" aria-hidden="true" href="#我的思考">#</a></h2>
<ul>
<li>
<p>ResNet 有效提取空间特征，但模型在<strong>连续转弯区域仍存在滞后</strong>。</p>
</li>
<li>
<p>真正部署前还需加入控制平滑性约束、sensor fusion、时延补偿等；</p>
</li>
<li>
<p>若加入车辆状态如速度、上帧角度，效果可能进一步优化。</p>
</li>
<li>
<p>可扩展方向包括：
使用 Transformer 替代 LSTM</p>
<p>引入 attention 模块</p>
<p>增加辅助状态输入（车速、扭矩等）</p>
</li>
</ul>
<h2 id="延伸阅读">延伸阅读<a hidden class="anchor" aria-hidden="true" href="#延伸阅读">#</a></h2>
<ul>
<li><a href="https://developer.nvidia.com/blog/deep-learning-self-driving-cars/">NVIDIA PilotNet</a></li>
<li><a href="https://arxiv.org/abs/1604.07316">End-to-End Learning for Self-Driving Cars (2016)</a></li>
</ul>
<hr>
<p><strong>下一篇预告：</strong><br>
LSTM在连续控制任务中的优势，以及与Transformer的对比。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="//localhost:1313/tags/cnn/">CNN</a></li>
      <li><a href="//localhost:1313/tags/lstm/">LSTM</a></li>
      <li><a href="//localhost:1313/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a></li>
      <li><a href="//localhost:1313/tags/%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%AD%A6%E4%B9%A0/">端到端学习</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<script src="/js/cursor-effects.js"></script>
<script>
  new CursorEffects({
    size: 2,
    shape: 'star',
    zIndex: 9999,
  });
</script>
</body>

</html>
